{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PepitoDataset import PepitoDataset\n",
    "from Models import PepitoModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = PepitoDataset(\"./dataset\")\n",
    "\n",
    "# Split the dataset into train and test and create the dataloaders\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "# Save the split indexes to reproduce the same split later\n",
    "np.save(\"train_indexes.npy\", train_dataset.indices)\n",
    "np.save(\"test_indexes.npy\", test_dataset.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsauv/Dev/pepito/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tsauv/Dev/pepito/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tsauv/Dev/pepito/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming PepitoModel, train_dataloader, and test_dataloader are already defined\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = PepitoModel(2).to(device)  # Output layer should have 2 neurons for two classes\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Added weight decay for regularization\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 502/502 [02:07<00:00,  3.93it/s, loss=0.242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 89.98%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:17<00:00,  7.37it/s, loss=0.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 92.15%\n",
      "--------------------------------------------------\n",
      "Epoch 2\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 502/502 [02:06<00:00,  3.97it/s, loss=0.15] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 94.73%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:12<00:00,  9.74it/s, loss=0.0836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 96.31%\n",
      "--------------------------------------------------\n",
      "Epoch 3\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 502/502 [02:03<00:00,  4.06it/s, loss=0.0837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 96.45%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:16<00:00,  7.75it/s, loss=0.0539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 97.73%\n",
      "--------------------------------------------------\n",
      "Epoch 4\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 502/502 [02:01<00:00,  4.12it/s, loss=0.0933] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 96.38%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:16<00:00,  7.81it/s, loss=0.0589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 97.21%\n",
      "--------------------------------------------------\n",
      "Epoch 5\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 502/502 [02:04<00:00,  4.03it/s, loss=0.0921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 95.93%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:12<00:00,  9.78it/s, loss=0.0523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 97.56%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    print(\"Training\")\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    tqdm_train_dataloader = tqdm(train_dataloader)\n",
    "    for i, (inputs, _, labels) in enumerate(tqdm_train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        tqdm_train_dataloader.set_postfix(loss=running_loss / (i + 1))\n",
    "\n",
    "    print(f\"Training Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "\n",
    "def test():\n",
    "    print(\"Testing\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tqdm_test_dataloader = tqdm(test_dataloader)\n",
    "        for i, (inputs, _, labels) in enumerate(tqdm_test_dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            tqdm_test_dataloader.set_postfix(loss=running_loss / (i + 1))\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Testing Accuracy: {accuracy:.2f}%\")\n",
    "    return running_loss, accuracy\n",
    "\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    train()\n",
    "    val_loss, val_accuracy = test()\n",
    "    scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"final_model_random.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def compute_saliency_maps(X, y, model):\n",
    "    model.eval()\n",
    "    X.requires_grad_()\n",
    "    scores = model(X)\n",
    "    score_max_index = scores.argmax(dim=1)\n",
    "    score_max = scores[:, score_max_index]\n",
    "    score_max.backward(torch.ones_like(score_max))\n",
    "    saliency, _ = torch.max(X.grad.data.abs(), dim=1)\n",
    "    return saliency\n",
    "\n",
    "def show_saliency_maps(data_loader, model):\n",
    "    model.eval()\n",
    "    for i, data in enumerate(data_loader):\n",
    "        inputs, _, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        saliency = compute_saliency_maps(inputs, labels, model)\n",
    "        saliency = saliency.cpu().numpy()\n",
    "        for j in range(inputs.size(0)):\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(inputs[j].detach().cpu().permute(1, 2, 0))\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(saliency[j], cmap=plt.cm.hot)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        if i == 1:\n",
    "            break\n",
    "\n",
    "model = PepitoModel(2).to(device)\n",
    "model.load_state_dict(torch.load(\"final_model_random.pt\"))\n",
    "# show_saliency_maps(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PepitoDataset import PepitoDataset\n",
    "from Models import PepitoModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the dataset\n",
    "dataset = PepitoDataset(\"./dataset\")\n",
    "\n",
    "# Split the dataset into train and test from the saved indexes\n",
    "train_indexes = np.load(\"train_indexes.npy\")\n",
    "test_indexes = np.load(\"test_indexes.npy\")\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indexes)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indexes)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "# Assuming PepitoModel, train_dataloader, and test_dataloader are already defined\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the models\n",
    "model = PepitoModel(2).to(device)  # Output layer should have 2 neurons for two classes\n",
    "box_model = YOLO(\"yolo11n.pt\").to(device)  # load an official model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 6.8ms\n",
      "Speed: 0.1ms preprocess, 6.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 7.2ms\n",
      "Speed: 0.0ms preprocess, 7.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 8.3ms\n",
      "Speed: 0.0ms preprocess, 8.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 2 tvs, 19.6ms\n",
      "Speed: 0.0ms preprocess, 19.6ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: tv 0.40, tv 0.28\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 7.8ms\n",
      "Speed: 0.0ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 0.0ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 15.1ms\n",
      "Speed: 0.0ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 8.1ms\n",
      "Speed: 0.0ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 toilet, 7.8ms\n",
      "Speed: 0.0ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: toilet 0.32\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 7.7ms\n",
      "Speed: 0.0ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.6ms\n",
      "Speed: 0.0ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 7.9ms\n",
      "Speed: 0.0ms preprocess, 7.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.0ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 7.3ms\n",
      "Speed: 0.0ms preprocess, 7.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 0.0ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 8.1ms\n",
      "Speed: 0.0ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 person, 8.9ms\n",
      "Speed: 0.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: person 0.30\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 toilet, 8.9ms\n",
      "Speed: 0.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: toilet 0.35\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 0.0ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 refrigerator, 11.6ms\n",
      "Speed: 0.0ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: refrigerator 0.27\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 refrigerator, 17.4ms\n",
      "Speed: 0.0ms preprocess, 17.4ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: refrigerator 0.25\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 0.0ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 person, 10.4ms\n",
      "Speed: 0.0ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: person 0.60\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 6.2ms\n",
      "Speed: 0.0ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: cat 0.84\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 0.0ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 refrigerator, 8.6ms\n",
      "Speed: 0.0ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: refrigerator 0.28\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.3ms\n",
      "Speed: 0.0ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 refrigerator, 5.9ms\n",
      "Speed: 0.0ms preprocess, 5.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: refrigerator 0.46\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 tv, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: tv 0.26\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 11.4ms\n",
      "Speed: 0.0ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: cat 0.80\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 16.5ms\n",
      "Speed: 0.0ms preprocess, 16.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: cat 0.47\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 8.6ms\n",
      "Speed: 0.0ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 1 clock, 13.3ms\n",
      "Speed: 0.0ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: cat 0.54, clock 0.42\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 0.0ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 12.1ms\n",
      "Speed: 0.0ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: cat 0.57\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 8.4ms\n",
      "Speed: 0.0ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 tv, 7.2ms\n",
      "Speed: 0.0ms preprocess, 7.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: tv 0.36\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 7.0ms\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 0.0ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.3ms\n",
      "Speed: 0.0ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.8ms\n",
      "Speed: 0.0ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.4ms\n",
      "Speed: 0.0ms preprocess, 6.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.0ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 toilet, 10.4ms\n",
      "Speed: 0.0ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: toilet 0.40\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 9.7ms\n",
      "Speed: 0.0ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: cat 0.33\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.7ms\n",
      "Speed: 0.0ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 9.2ms\n",
      "Speed: 0.0ms preprocess, 9.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.3ms\n",
      "Speed: 0.0ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 refrigerator, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: refrigerator 0.27\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 tv, 10.5ms\n",
      "Speed: 0.0ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: tv 0.28\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.8ms\n",
      "Speed: 0.0ms preprocess, 6.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 0.0ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 13.8ms\n",
      "Speed: 0.0ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 refrigerator, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: refrigerator 0.25\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 0.0ms preprocess, 15.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 16.2ms\n",
      "Speed: 0.0ms preprocess, 16.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: cat 0.28\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 0.0ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 7.1ms\n",
      "Speed: 0.0ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 1 refrigerator, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: cat 0.72, refrigerator 0.42\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 0.0ms preprocess, 14.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.7ms\n",
      "Speed: 0.0ms preprocess, 6.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.1ms\n",
      "Speed: 0.0ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 person, 1 toothbrush, 6.7ms\n",
      "Speed: 0.0ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: person 0.58, toothbrush 0.33\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 8.8ms\n",
      "Speed: 0.0ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 0.0ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 person, 7.2ms\n",
      "Speed: 0.0ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: person 0.50\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 6.4ms\n",
      "Speed: 0.0ms preprocess, 6.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: cat 0.74\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 0.0ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 13.8ms\n",
      "Speed: 0.0ms preprocess, 13.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 0.0ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 toilet, 6.1ms\n",
      "Speed: 0.0ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: toilet 0.29\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.7ms\n",
      "Speed: 0.0ms preprocess, 6.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 7.8ms\n",
      "Speed: 0.0ms preprocess, 7.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 1 toilet, 9.7ms\n",
      "Speed: 0.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: cat 0.82, toilet 0.28\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 9.3ms\n",
      "Speed: 0.0ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 0.0ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 tv, 7.3ms\n",
      "Speed: 0.0ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: tv 0.39\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 15.3ms\n",
      "Speed: 0.0ms preprocess, 15.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 refrigerator, 7.8ms\n",
      "Speed: 0.0ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: refrigerator 0.32\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 6.3ms\n",
      "Speed: 0.0ms preprocess, 6.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 1 refrigerator, 9.6ms\n",
      "Speed: 0.0ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: cat 0.83, refrigerator 0.29\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 9.3ms\n",
      "Speed: 0.0ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: cat 0.89\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 (no detections), 8.9ms\n",
      "Speed: 0.0ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: \n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 toilet, 10.7ms\n",
      "Speed: 0.0ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: out, Predicted: in\n",
      "Detected objects: toilet 0.33\n",
      "--------------------------------------------------\n",
      "\n",
      "0: 640x640 1 cat, 13.3ms\n",
      "Speed: 0.0ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "True label: in, Predicted: out\n",
      "Detected objects: cat 0.86\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from PepitoDataset import LABEL_MAP\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "\n",
    "reversed_label_map = {v: k for k, v in LABEL_MAP.items()}\n",
    "model.load_state_dict(torch.load(\"final_model_random.pt\"))\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "\n",
    "misclassified_dict = {\n",
    "    \"no_objects\": 0,\n",
    "    \"unsure_objects\": 0,\n",
    "    \"cat_detected\": 0,\n",
    "}\n",
    "\n",
    "for i, data in enumerate(test_dataloader):\n",
    "    inputs, _, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    for j in range(inputs.size(0)):\n",
    "        total += 1\n",
    "        if predicted[j] != labels[j]:\n",
    "            # Compute saliency map\n",
    "            saliency = compute_saliency_maps(inputs[j].unsqueeze(0), labels[j].unsqueeze(0), model)\n",
    "            saliency = saliency.cpu().numpy()\n",
    "\n",
    "            # Convert tensor to numpy array and denormalize\n",
    "            img = inputs[j].detach().cpu().permute(1, 2, 0).numpy()\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "\n",
    "            # # Plot original image\n",
    "            # plt.subplot(1, 3, 1)\n",
    "            # plt.imshow(img)\n",
    "            # plt.axis('off')\n",
    "            # plt.title(\"Original Image\")\n",
    "\n",
    "\n",
    "            # Plot image with bounding boxes\n",
    "            bbox_img = transforms.Resize((640, 640))(inputs[j].unsqueeze(0))\n",
    "            bbox_results = box_model(bbox_img)\n",
    "            img_with_boxes = bbox_img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "            img_with_boxes = (img_with_boxes * 255).astype(np.uint8)\n",
    "            img_with_boxes = cv2.cvtColor(img_with_boxes, cv2.COLOR_RGB2BGR)  # Convert to BGR format for OpenCV\n",
    "            for result in bbox_results:\n",
    "                xyxy = result.boxes.xyxy.cpu().numpy()  # top-left-x, top-left-y, bottom-right-x, bottom-right-y\n",
    "                names = [result.names[cls.item()] for cls in result.boxes.cls.int()]  # class name of each box\n",
    "                confs = result.boxes.conf.cpu().numpy()  # confidence score of each box\n",
    "                for box, name, conf in zip(xyxy, names, confs):\n",
    "                    cv2.rectangle(img_with_boxes, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
    "                    cv2.putText(img_with_boxes, f\"{name} {conf:.2f}\", (int(box[0]), int(box[1]) + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "            # plt.subplot(1, 3, 2)\n",
    "            # plt.imshow(img_with_boxes)\n",
    "            # plt.axis('off')\n",
    "            # plt.title(\"Image with Bounding Boxes\")\n",
    "\n",
    "            # # Plot saliency map\n",
    "            # plt.subplot(1, 3, 3)\n",
    "            # plt.imshow(saliency[0], cmap=plt.cm.hot)\n",
    "            # plt.axis('off')\n",
    "            # plt.title(\"Saliency Map\")\n",
    "\n",
    "            # plt.show()\n",
    "            print(f\"True label: {reversed_label_map[labels[j].item()]}, Predicted: {reversed_label_map[predicted[j].item()]}\")\n",
    "\n",
    "            print(f\"Detected objects: {', '.join([f'{name} {conf:.2f}' for name, conf in zip(names, confs)])}\")\n",
    "\n",
    "            if len(names) == 0:\n",
    "                misclassified_dict[\"no_objects\"] += 1\n",
    "            elif \"cat\" in names:\n",
    "                misclassified_dict[\"cat_detected\"] += 1\n",
    "            else:\n",
    "                misclassified_dict[\"unsure_objects\"] += 1\n",
    "            print(\"--------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.56%\n",
      "Total misclassified: 98\n",
      "\tno_objects: 64\n",
      "\tunsure_objects: 21\n",
      "\tcat_detected: 13\n",
      "Total : 4015\n"
     ]
    }
   ],
   "source": [
    "total_misclassified = sum(misclassified_dict.values())\n",
    "print(f\"Accuracy: {100 * (total - total_misclassified) / total:.2f}%\")\n",
    "print(f\"Total misclassified: {total_misclassified}\")\n",
    "for key, value in misclassified_dict.items():\n",
    "    print(f\"\\t{key}: {value}\")\n",
    "print(f\"Total : {total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
