{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PepitoDataset import LimitedPepitoDataset\n",
    "from Models import PepitoModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = LimitedPepitoDataset(\"./yolo_results.json\", \"cat_detected\")\n",
    "\n",
    "# Split the dataset into train and test and create the dataloaders\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "# Save the split indexes to reproduce the same split later\n",
    "np.save(\"train_indexes_limited.npy\", train_dataset.indices)\n",
    "np.save(\"test_indexes_limited.npy\", test_dataset.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsauv/Dev/pepito/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tsauv/Dev/pepito/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tsauv/Dev/pepito/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming PepitoModel, train_dataloader, and test_dataloader are already defined\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = PepitoModel(2).to(device)  # Output layer should have 2 neurons for two classes\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Added weight decay for regularization\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train():\n",
    "    print(\"Training\")\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    tqdm_train_dataloader = tqdm(train_dataloader)\n",
    "    for i, (inputs, _, labels) in enumerate(tqdm_train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        tqdm_train_dataloader.set_postfix(loss=running_loss / (i + 1))\n",
    "\n",
    "    print(f\"Training Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "\n",
    "def test():\n",
    "    print(\"Testing\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tqdm_test_dataloader = tqdm(test_dataloader)\n",
    "        for i, (inputs, _, labels) in enumerate(tqdm_test_dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            tqdm_test_dataloader.set_postfix(loss=running_loss / (i + 1))\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Testing Accuracy: {accuracy:.2f}%\")\n",
    "    return running_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 378/378 [01:12<00:00,  5.20it/s, loss=0.334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 83.69%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:11<00:00,  8.27it/s, loss=0.0324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 99.47%\n",
      "--------------------------------------------------\n",
      "Epoch 2\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 378/378 [01:07<00:00,  5.61it/s, loss=0.735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 55.56%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:10<00:00,  9.12it/s, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n",
      "Epoch 3\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 378/378 [01:06<00:00,  5.68it/s, loss=0.686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.33%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:08<00:00, 11.37it/s, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n",
      "Epoch 4\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 378/378 [01:05<00:00,  5.79it/s, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.30%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:09<00:00,  9.56it/s, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n",
      "Epoch 5\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 378/378 [01:05<00:00,  5.81it/s, loss=0.69] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.32%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:07<00:00, 12.12it/s, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    train()\n",
    "    val_loss, val_accuracy = test()\n",
    "    scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"limited_set.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsauv/Dev/pepito/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tsauv/Dev/pepito/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tsauv/Dev/pepito/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PepitoDataset import LimitedPepitoDataset\n",
    "from Models import LightPepitoModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the dataset\n",
    "dataset = LimitedPepitoDataset(\"./yolo_results.json\", \"cat_detected\")\n",
    "\n",
    "# Split the dataset into train and test from the saved indexes\n",
    "train_indexes = np.load(\"train_indexes_limited.npy\")\n",
    "test_indexes = np.load(\"test_indexes_limited.npy\")\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indexes)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indexes)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "# Assuming PepitoModel, train_dataloader, and test_dataloader are already defined\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the models\n",
    "model = LightPepitoModel(2).to(device)  # Output layer should have 2 neurons for two classesimport torch\n",
    "# model.load_state_dict(torch.load(\"limited_set_lightweight.pt\"))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Added weight decay for regularization\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:28<00:00,  2.14it/s, loss=0.818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 52.16%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:15<00:00,  3.04it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.15%\n",
      "--------------------------------------------------\n",
      "Epoch 2\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:25<00:00,  2.21it/s, loss=0.98] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 54.66%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:15<00:00,  3.02it/s, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n",
      "Epoch 3\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:27<00:00,  2.17it/s, loss=0.811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.35%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:16<00:00,  2.97it/s, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.25%\n",
      "--------------------------------------------------\n",
      "Epoch 4\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:23<00:00,  2.27it/s, loss=0.779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.32%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:16<00:00,  2.96it/s, loss=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n",
      "Epoch 5\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:25<00:00,  2.22it/s, loss=0.745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.22%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:17<00:00,  2.80it/s, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n",
      "Epoch 6\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:29<00:00,  2.10it/s, loss=0.8]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.28%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:16<00:00,  2.92it/s, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n",
      "Epoch 7\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:27<00:00,  2.15it/s, loss=0.711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.28%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:17<00:00,  2.77it/s, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n",
      "Epoch 8\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:27<00:00,  2.17it/s, loss=0.76] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.29%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:16<00:00,  2.93it/s, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n",
      "Epoch 9\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:28<00:00,  2.13it/s, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.33%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:16<00:00,  2.92it/s, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n",
      "Epoch 10\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:26<00:00,  2.18it/s, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.38%\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:17<00:00,  2.81it/s, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 55.29%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "early_stopping = True\n",
    "early_stopping_counter = 0\n",
    "early_stopping_patience = 5\n",
    "early_stopping_loss = None\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    train()\n",
    "    val_loss, val_accuracy = test()\n",
    "    scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "\n",
    "    if early_stopping:\n",
    "        if early_stopping_loss is None or val_loss < early_stopping_loss:\n",
    "            early_stopping_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"limited_set_lightweight.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def compute_saliency_maps(X, y, model):\n",
    "    model.eval()\n",
    "    X.requires_grad_()\n",
    "    scores = model(X)\n",
    "    score_max_index = scores.argmax(dim=1)\n",
    "    score_max = scores[:, score_max_index]\n",
    "    score_max.backward(torch.ones_like(score_max))\n",
    "    saliency, _ = torch.max(X.grad.data.abs(), dim=1)\n",
    "    return saliency\n",
    "\n",
    "def show_saliency_maps(data_loader, model):\n",
    "    model.eval()\n",
    "    for i, data in enumerate(data_loader):\n",
    "        inputs, _, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        saliency = compute_saliency_maps(inputs, labels, model)\n",
    "        saliency = saliency.cpu().numpy()\n",
    "        for j in range(inputs.size(0)):\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(inputs[j].detach().cpu().permute(1, 2, 0))\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(saliency[j], cmap=plt.cm.hot)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        if i == 1:\n",
    "            break\n",
    "\n",
    "model = LightPepitoModel(2).to(device)\n",
    "model.load_state_dict(torch.load(\"limited_set_lightweight.pt\"))\n",
    "show_saliency_maps(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsauv/Dev/pepito/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tsauv/Dev/pepito/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from PepitoDataset import PepitoDataset\n",
    "from Models import PepitoModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the dataset\n",
    "dataset = LimitedPepitoDataset(\"./yolo_results.json\", \"cat_detected\")\n",
    "\n",
    "# Split the dataset into train and test from the saved indexes\n",
    "train_indexes = np.load(\"train_indexes_limited.npy\")\n",
    "test_indexes = np.load(\"test_indexes_limited.npy\")\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indexes)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indexes)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "# Assuming PepitoModel, train_dataloader, and test_dataloader are already defined\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the models\n",
    "model = PepitoModel(2).to(device)  # Output layer should have 2 neurons for two classes\n",
    "box_model = YOLO(\"yolo11n.pt\").to(device)  # load an official model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PepitoDataset import LABEL_MAP\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "\n",
    "reversed_label_map = {v: k for k, v in LABEL_MAP.items()}\n",
    "model.load_state_dict(torch.load(\"limited_set_lightweight.pt\"))\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "\n",
    "misclassified = 0\n",
    "\n",
    "for i, data in enumerate(test_dataloader):\n",
    "    inputs, _, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    for j in range(inputs.size(0)):\n",
    "        total += 1\n",
    "        if predicted[j] != labels[j]:\n",
    "            misclassified += 1\n",
    "            # Compute saliency map\n",
    "            saliency = compute_saliency_maps(inputs[j].unsqueeze(0), labels[j].unsqueeze(0), model)\n",
    "            saliency = saliency.cpu().numpy()\n",
    "\n",
    "            # Convert tensor to numpy array and denormalize\n",
    "            img = inputs[j].detach().cpu().permute(1, 2, 0).numpy()\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "\n",
    "            # Plot original image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Original Image\")\n",
    "\n",
    "\n",
    "            # Plot saliency map\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(saliency[0], cmap=plt.cm.hot)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Saliency Map\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified: 6/3017\n",
      "Accuracy: 99.80%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Misclassified: {misclassified}/{total}\")\n",
    "print(f\"Accuracy: {(total - misclassified) / total * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
